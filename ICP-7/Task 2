{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Task 2","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNRRvsHtVJtDmiUDpX7KYBW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dZ-9IQht9dlQ","colab_type":"code","outputId":"725ea3d0-5b56-4b66-966d-703639d2754a","executionInfo":{"status":"ok","timestamp":1583519824452,"user_tz":360,"elapsed":98466,"user":{"displayName":"divya reddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggs2myGpo2b2t9Kz29mUuWgLcVrvayYSRaaD3Op_TQ=s64","userId":"04397886005787697308"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["from sklearn.datasets import fetch_20newsgroups\n","import  pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn import metrics\n","from sklearn.pipeline import Pipeline\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","\n","categories = ['alt.atheism', 'talk.religion.misc',\n","             'comp.graphics', 'rec.motorcycles', 'sci.space']\n","\n","twenty_train = fetch_20newsgroups(subset='train', shuffle=True, categories=categories)\n","\n","tfidf_Vect = TfidfVectorizer()\n","X_train_tfidf = tfidf_Vect.fit_transform(twenty_train.data)\n","# print(tfidf_Vect.vocabulary_)\n","clf = SVC()\n","clf.fit(X_train_tfidf, twenty_train.target)\n","\n","twenty_test = fetch_20newsgroups(subset='test', shuffle=True, categories=categories)\n","X_test_tfidf = tfidf_Vect.transform(twenty_test.data)\n","\n","predicted = clf.predict(X_test_tfidf)\n","\n","\n","tfidf_Vect1 = TfidfVectorizer(ngram_range=(1,2))\n","X_train_tfidf1 = tfidf_Vect1.fit_transform(twenty_train.data)\n","# print(tfidf_Vect.vocabulary_)\n","clf1 = SVC()\n","clf1.fit(X_train_tfidf1, twenty_train.target)\n","X_test_tfidf1 = tfidf_Vect1.transform(twenty_test.data)\n","predicted1 = clf1.predict(X_test_tfidf1)\n","\n","tfidf_Vect2 = TfidfVectorizer(stop_words='english')\n","X_train_tfidf2 = tfidf_Vect2.fit_transform(twenty_train.data)\n","# print(tfidf_Vect.vocabulary_)\n","clf2 = SVC()\n","clf2.fit(X_train_tfidf2, twenty_train.target)\n","X_test_tfidf2 = tfidf_Vect2.transform(twenty_test.data)\n","predicted2 = clf2.predict(X_test_tfidf2)\n","\n","score = metrics.accuracy_score(twenty_test.target, predicted)\n","print('SVC score is ' + str(score))\n","\n","score1 = metrics.accuracy_score(twenty_test.target, predicted1)\n","print('using npgram score is ' + str(score1))\n","\n","score2 = metrics.accuracy_score(twenty_test.target, predicted2)\n","print('using stop words score is ' + str(score2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["SVC score is 0.8949171901770417\n","using npgram score is 0.8949171901770417\n","using stop words score is 0.9006282124500286\n"],"name":"stdout"}]}]}